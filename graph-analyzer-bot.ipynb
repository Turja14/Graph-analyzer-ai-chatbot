{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# STEP 1: Install Required Libraries\n# ============================================================================\nprint(\"Step 1: Installing required libraries...\")\nimport sys\nimport subprocess\n\n# Install groq, pillow, and gradio\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"groq\", \"pillow\", \"gradio\", \"-q\"])\nprint(\"âœ… Libraries installed successfully!\")","metadata":{"_uuid":"e7b32e18-0499-4264-b0e4-fda934f5926e","_cell_guid":"bf7fd518-f8a1-475a-b4d3-0a526f6e5619","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-04T06:48:20.113942Z","iopub.execute_input":"2025-12-04T06:48:20.114244Z","iopub.status.idle":"2025-12-04T06:48:26.080816Z","shell.execute_reply.started":"2025-12-04T06:48:20.114227Z","shell.execute_reply":"2025-12-04T06:48:26.079750Z"}},"outputs":[{"name":"stdout","text":"Step 1: Installing required libraries...\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 68.6/68.6 kB 1.9 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 444.8/444.8 kB 9.8 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 40.6 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Libraries installed successfully!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================================================================\n# STEP 2: Import Libraries\n# ============================================================================\nprint(\"\\nStep 2: Importing libraries...\")\nimport time\ntime.sleep(1)  # Give a moment for installation to complete\n\nfrom groq import Groq\nimport base64\nfrom PIL import Image\nimport gradio as gr\nimport io","metadata":{"_uuid":"f0b46c3b-5dca-42eb-a5ed-bd9507f1b352","_cell_guid":"455fc0a1-6e1b-4b64-b34d-4b0b1a288bd4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-04T06:48:26.081793Z","iopub.execute_input":"2025-12-04T06:48:26.082030Z","iopub.status.idle":"2025-12-04T06:48:27.086542Z","shell.execute_reply.started":"2025-12-04T06:48:26.082011Z","shell.execute_reply":"2025-12-04T06:48:27.085398Z"}},"outputs":[{"name":"stdout","text":"\nStep 2: Importing libraries...\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================================\n# STEP 3: Set Up Groq API Key\n# ============================================================================\nprint(\"\\nStep 3: Setting up Groq API...\")\nAPI_KEY = \"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\"\nclient = Groq(api_key=API_KEY)","metadata":{"_uuid":"c19f2066-4dd1-4313-90ed-c348e7eb3f2c","_cell_guid":"2b73d3ea-f26a-4a92-a8ce-2a05927ec80f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-04T06:48:27.087674Z","iopub.execute_input":"2025-12-04T06:48:27.087935Z","iopub.status.idle":"2025-12-04T06:48:27.122200Z","shell.execute_reply.started":"2025-12-04T06:48:27.087916Z","shell.execute_reply":"2025-12-04T06:48:27.121131Z"}},"outputs":[{"name":"stdout","text":"\nStep 3: Setting up Groq API...\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================================================================\n# STEP 4: Helper Functions\n# ============================================================================\nprint(\"\\nStep 4: Creating helper functions...\")\n\ndef encode_image_to_base64(image):\n    \"\"\"Convert PIL Image to base64 data URL\"\"\"\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n    data_url = f\"data:image/png;base64,{img_str}\"\n    return data_url\n\ndef analyze_graph(image, question, history):\n    \"\"\"Analyze the graph and return response\"\"\"\n    if image is None:\n        return history + [(\"Please upload an image first.\", None)]\n    \n    if not question.strip():\n        return history + [(\"Please ask a question about the graph.\", None)]\n    \n    try:\n        # Convert image to base64\n        image_url = encode_image_to_base64(image)\n        \n        # Call Groq API\n        completion = client.chat.completions.create(\n            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": image_url\n                            }\n                        },\n                        {\n                            \"type\": \"text\",\n                            \"text\": question\n                        }\n                    ]\n                }\n            ],\n            temperature=0.7,\n            max_tokens=2048,\n            top_p=1,\n            stream=False\n        )\n        \n        response = completion.choices[0].message.content\n        history = history + [(question, response)]\n        return history\n    \n    except Exception as e:\n        error_msg = f\"Error: {str(e)}\"\n        history = history + [(question, error_msg)]\n        return history","metadata":{"_uuid":"61ce1cc2-c2c8-4d9a-8970-f5cef7af23fc","_cell_guid":"9825dd79-629c-4002-a1ca-7784cb02e65b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-04T06:48:27.124058Z","iopub.execute_input":"2025-12-04T06:48:27.124302Z","iopub.status.idle":"2025-12-04T06:48:27.131570Z","shell.execute_reply.started":"2025-12-04T06:48:27.124284Z","shell.execute_reply":"2025-12-04T06:48:27.130496Z"}},"outputs":[{"name":"stdout","text":"\nStep 4: Creating helper functions...\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# ============================================================================\n# STEP 5: Gradio Interface\n# ============================================================================\nprint(\"\\nStep 5: Creating Gradio interface...\")\n\nwith gr.Blocks(title=\"AI Graph Analyzer\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\n        \"\"\"\n        # ğŸ¤– AI Graph Analyzer Chatbot\n        ### Powered by Groq & Llama Vision\n        \n        Upload a graph, chart, or diagram and ask questions about it!\n        \"\"\"\n    )\n    \n    with gr.Row():\n        with gr.Column(scale=1):\n            image_input = gr.Image(\n                type=\"pil\",\n                label=\"Upload Your Graph/Chart\",\n                height=400\n            )\n            gr.Markdown(\"**Examples:** Line graphs, bar charts, pie charts, scatter plots, etc.\")\n        \n        with gr.Column(scale=1):\n            chatbot = gr.Chatbot(\n                label=\"Conversation\",\n                height=400,\n                show_label=True\n            )\n            \n            question_input = gr.Textbox(\n                placeholder=\"Ask a question about the graph...\",\n                label=\"Your Question\",\n                lines=2\n            )\n            \n            with gr.Row():\n                submit_btn = gr.Button(\"ğŸ” Analyze\", variant=\"primary\")\n                clear_btn = gr.Button(\"ğŸ—‘ï¸ Clear Chat\")\n    \n    gr.Markdown(\n        \"\"\"\n        ### Example Questions:\n        - What is the overall trend shown in this graph?\n        - What are the highest and lowest values?\n        - Compare the values between different categories\n        - What insights can you derive from this chart?\n        - Explain what this diagram represents\n        \"\"\"\n    )\n    \n    # Event handlers\n    submit_btn.click(\n        fn=analyze_graph,\n        inputs=[image_input, question_input, chatbot],\n        outputs=chatbot\n    ).then(\n        lambda: \"\",\n        outputs=question_input\n    )\n    \n    question_input.submit(\n        fn=analyze_graph,\n        inputs=[image_input, question_input, chatbot],\n        outputs=chatbot\n    ).then(\n        lambda: \"\",\n        outputs=question_input\n    )\n    \n    clear_btn.click(\n        lambda: [],\n        outputs=chatbot\n    )\n\n# Launch the interface\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸš€ Launching Gradio interface...\")\nprint(\"=\"*60)\n\ndemo.launch(share=True, debug=True)","metadata":{"_uuid":"e20fa2fa-eb41-4a2e-adc3-0844844ea43a","_cell_guid":"7cc8d92f-3dec-455d-aa90-c14585550eb7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-12-04T06:48:27.132275Z","iopub.execute_input":"2025-12-04T06:48:27.132545Z","execution_failed":"2025-12-04T09:25:45.718Z"}},"outputs":[{"name":"stdout","text":"\nStep 5: Creating Gradio interface...\n\n============================================================\nğŸš€ Launching Gradio interface...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/1376310908.py:26: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n  chatbot = gr.Chatbot(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7861\n* Running on public URL: https://cf18fe231484846838.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://cf18fe231484846838.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null}]}